{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1caf1691-1415-4c24-a845-255c664ec202",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T04:38:42.371165Z",
     "iopub.status.busy": "2024-02-21T04:38:42.370661Z",
     "iopub.status.idle": "2024-02-21T04:38:56.692762Z",
     "shell.execute_reply": "2024-02-21T04:38:56.690850Z",
     "shell.execute_reply.started": "2024-02-21T04:38:42.371111Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from datasets import load_dataset\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import numpy as np\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb3a0d4-67aa-4ea6-b8c2-40dc14052157",
   "metadata": {},
   "source": [
    "## FLAN T5 prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d05068e-69f9-4d51-9d5c-65410b0c60a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T04:38:56.697536Z",
     "iopub.status.busy": "2024-02-21T04:38:56.696528Z",
     "iopub.status.idle": "2024-02-21T04:39:01.839972Z",
     "shell.execute_reply": "2024-02-21T04:39:01.838463Z",
     "shell.execute_reply.started": "2024-02-21T04:38:56.697476Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/home/hoannc8/envs/torch_py310/lib/python3.10/site-packages/transformers/generation/utils.py:1133: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> Wie ich er bitten?</s>\n"
     ]
    }
   ],
   "source": [
    "model_name = \"google/flan-t5-small\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "device = \"cuda:2\"\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name, device_map=device)\n",
    "\n",
    "input_text = \"translate English to German: How old are you?\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n",
    "\n",
    "outputs = model.generate(input_ids)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c631a2-0560-4460-8b8b-e6e9e70dd9c5",
   "metadata": {},
   "source": [
    "## Zero shot sentiment classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35f218c8-29bb-4c66-b882-4d3973e3758e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T04:39:01.841655Z",
     "iopub.status.busy": "2024-02-21T04:39:01.841397Z",
     "iopub.status.idle": "2024-02-21T04:39:01.850391Z",
     "shell.execute_reply": "2024-02-21T04:39:01.849480Z",
     "shell.execute_reply.started": "2024-02-21T04:39:01.841628Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Please classify the sentiment of the following statement as 'positive' or 'negative':\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruct_promt = \"Please classify the sentiment of the following statement as 'positive' or 'negative':\"\n",
    "instruct_promt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3304991-13e4-41b8-b70d-919a411b7275",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T04:39:01.852123Z",
     "iopub.status.busy": "2024-02-21T04:39:01.851432Z",
     "iopub.status.idle": "2024-02-21T04:39:01.866030Z",
     "shell.execute_reply": "2024-02-21T04:39:01.864416Z",
     "shell.execute_reply.started": "2024-02-21T04:39:01.852095Z"
    }
   },
   "outputs": [],
   "source": [
    "input_text = \"I hate this film. It's so boring!\"\n",
    "input_prompt = instruct_promt + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "419bcccb-a5e1-4060-8cb7-17ae841e2927",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T04:51:09.107611Z",
     "iopub.status.busy": "2024-02-21T04:51:09.106582Z",
     "iopub.status.idle": "2024-02-21T04:51:09.201487Z",
     "shell.execute_reply": "2024-02-21T04:51:09.199900Z",
     "shell.execute_reply.started": "2024-02-21T04:51:09.107524Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(input_prompt, return_tensors=\"pt\")\n",
    "inputs = inputs.to(device)\n",
    "outputs = model.generate(inputs['input_ids'])\n",
    "tokenizer.batch_decode(outputs, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acf87e7-9572-454e-85bd-d6dfecbda879",
   "metadata": {},
   "source": [
    "### Working with IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb13c9ac-ce24-4c6b-a015-bc6633bff4e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T04:39:01.933561Z",
     "iopub.status.busy": "2024-02-21T04:39:01.933353Z",
     "iopub.status.idle": "2024-02-21T04:39:13.723085Z",
     "shell.execute_reply": "2024-02-21T04:39:13.721288Z",
     "shell.execute_reply.started": "2024-02-21T04:39:01.933539Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'I love sci-fi and am willing to put up with a lot. Sci-fi movies/TV are usually underfunded, under-appreciated and misunderstood. I tried to like this, I really did, but it is to good TV sci-fi as Babylon 5 is to Star Trek (the original). Silly prosthetics, cheap cardboard sets, stilted dialogues, CG that doesn\\'t match the background, and painfully one-dimensional characters cannot be overcome with a \\'sci-fi\\' setting. (I\\'m sure there are those of you out there who think Babylon 5 is good sci-fi TV. It\\'s not. It\\'s clich√©d and uninspiring.) While US viewers might like emotion and character development, sci-fi is a genre that does not take itself seriously (cf. Star Trek). It may treat important issues, yet not as a serious philosophy. It\\'s really difficult to care about the characters here as they are not simply foolish, just missing a spark of life. Their actions and reactions are wooden and predictable, often painful to watch. The makers of Earth KNOW it\\'s rubbish as they have to always say \"Gene Roddenberry\\'s Earth...\" otherwise people would not continue watching. Roddenberry\\'s ashes must be turning in their orbit as this dull, cheap, poorly edited (watching it without advert breaks really brings this home) trudging Trabant of a show lumbers into space. Spoiler. So, kill off a main character. And then bring him back as another actor. Jeeez! Dallas all over again.',\n",
       " 'labels': 0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"imdb\", split=\"test\")\n",
    "dataset = dataset.rename_column(\"label\", \"labels\") #match trainer column\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be419328-a7f9-4e9d-bc7c-4d53eb92acaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T04:39:13.730868Z",
     "iopub.status.busy": "2024-02-21T04:39:13.730408Z",
     "iopub.status.idle": "2024-02-21T04:39:13.877115Z",
     "shell.execute_reply": "2024-02-21T04:39:13.875458Z",
     "shell.execute_reply.started": "2024-02-21T04:39:13.730821Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(instruct_promt+dataset[0]['text'], return_tensors=\"pt\")\n",
    "inputs = inputs.to(device)\n",
    "outputs = model.generate(**inputs)\n",
    "tokenizer.batch_decode(outputs, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b881358-c9d4-4ae1-956e-25cd82f537f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T04:41:15.251089Z",
     "iopub.status.busy": "2024-02-21T04:41:15.250367Z",
     "iopub.status.idle": "2024-02-21T04:41:15.260480Z",
     "shell.execute_reply": "2024-02-21T04:41:15.259158Z",
     "shell.execute_reply.started": "2024-02-21T04:41:15.251015Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36d4ba51-5cf2-4374-96bf-3a96da24c4a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T04:41:23.767451Z",
     "iopub.status.busy": "2024-02-21T04:41:23.766764Z",
     "iopub.status.idle": "2024-02-21T04:41:23.777609Z",
     "shell.execute_reply": "2024-02-21T04:41:23.776082Z",
     "shell.execute_reply.started": "2024-02-21T04:41:23.767395Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 382])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['attention_mask'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0713a6-1860-4005-9869-f75698765114",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-21T04:39:15.869176Z",
     "iopub.status.idle": "2024-02-21T04:39:15.869857Z",
     "shell.execute_reply": "2024-02-21T04:39:15.869545Z",
     "shell.execute_reply.started": "2024-02-21T04:39:15.869511Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer([instruct_promt+text for text in examples[\"text\"]],\n",
    "                     truncation=True,\n",
    "                     padding=\"max_length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db03c345-df09-44ce-9977-e72e432c9b32",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-21T04:39:15.872222Z",
     "iopub.status.idle": "2024-02-21T04:39:15.872919Z",
     "shell.execute_reply": "2024-02-21T04:39:15.872582Z",
     "shell.execute_reply.started": "2024-02-21T04:39:15.872551Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenized_dataset = dataset.map(preprocess_function, batched=True, num_proc=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37ea8f4-0270-484c-a80f-e6b29d112b8d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-21T04:39:15.875481Z",
     "iopub.status.idle": "2024-02-21T04:39:15.876167Z",
     "shell.execute_reply": "2024-02-21T04:39:15.875837Z",
     "shell.execute_reply.started": "2024-02-21T04:39:15.875805Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenized_dataset[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4269c93-e0e1-433b-b7f5-0b4489aca719",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-21T04:39:15.877989Z",
     "iopub.status.idle": "2024-02-21T04:39:15.878758Z",
     "shell.execute_reply": "2024-02-21T04:39:15.878450Z",
     "shell.execute_reply.started": "2024-02-21T04:39:15.878418Z"
    }
   },
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"f1\")\n",
    "def compute_metrics(eval_pred):\n",
    "    print(eval_pred)\n",
    "    # predictions, labels = eval_pred\n",
    "    \n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    return metric.compute(predictions=predictions,\n",
    "                          references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aea1e20-3844-4bb8-a451-5a90a813f566",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-21T04:39:15.880585Z",
     "iopub.status.idle": "2024-02-21T04:39:15.881342Z",
     "shell.execute_reply": "2024-02-21T04:39:15.881151Z",
     "shell.execute_reply.started": "2024-02-21T04:39:15.881130Z"
    }
   },
   "outputs": [],
   "source": [
    "# eval\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../results/promting_T5\",\n",
    "    per_device_eval_batch_size=64,\n",
    "    evaluation_strategy=\"epoch\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    eval_dataset=tokenized_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f129856b-bd7e-43c5-998e-8b05b7c8a2b3",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-21T04:39:15.883436Z",
     "iopub.status.idle": "2024-02-21T04:39:15.883907Z",
     "shell.execute_reply": "2024-02-21T04:39:15.883721Z",
     "shell.execute_reply.started": "2024-02-21T04:39:15.883701Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluation_results = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7821624-59dd-4d24-9995-f0e87ac2f99d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-21T04:39:15.885318Z",
     "iopub.status.idle": "2024-02-21T04:39:15.885718Z",
     "shell.execute_reply": "2024-02-21T04:39:15.885534Z",
     "shell.execute_reply.started": "2024-02-21T04:39:15.885516Z"
    }
   },
   "outputs": [],
   "source": [
    "def postprocess_text(predictions, labels):\n",
    "    predictions = [prediction.strip() for prediction in predictions]\n",
    "    labels = [label2id[label.strip()] for label in labels]\n",
    "\n",
    "    for idx in range(len(predictions)):\n",
    "        if predictions[idx] in label2id:\n",
    "           predictions[idx] = label2id[predictions[idx]]\n",
    "        else:\n",
    "            predictions[idx] = '-100'\n",
    "    return predictions, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a7b9f7-dcdd-4b33-ad1e-fc432da4915a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce76d7e-91a3-46fa-8958-b2086c5c78be",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-21T04:39:15.889298Z",
     "iopub.status.idle": "2024-02-21T04:39:15.889931Z",
     "shell.execute_reply": "2024-02-21T04:39:15.889740Z",
     "shell.execute_reply.started": "2024-02-21T04:39:15.889720Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_prompt(examples, top_k_indices, corpus, labels, id2label):\n",
    "    sentences = examples[\"text\"]\n",
    "    prompts = []\n",
    "    for index, _ in enumerate(zip(sentences)):\n",
    "        prompt = 'Here are examples of texts and their sentiments'\n",
    "        top_indexs = top_k_indices[index]['top_index']\n",
    "        for top_index in top_indexs:\n",
    "            top_sentence = corpus[top_index]\n",
    "            top_label = id2label[str(labels[top_index])]\n",
    "            prompt = \" \".join(\n",
    "                [\n",
    "                    prompt,\n",
    "                    \". Text: \", \n",
    "                    top_sentence,\n",
    "                    \". Sentiment: \",\n",
    "                    top_label\n",
    "                ]\n",
    "            )\n",
    "        prompts.append(prompt)\n",
    "    \n",
    "    examples[\"prompt\"] = prompts\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaea6350-f71e-4ed5-b1b5-40be992782ef",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-21T04:39:15.891358Z",
     "iopub.status.idle": "2024-02-21T04:39:15.892075Z",
     "shell.execute_reply": "2024-02-21T04:39:15.891871Z",
     "shell.execute_reply.started": "2024-02-21T04:39:15.891851Z"
    }
   },
   "outputs": [],
   "source": [
    "input_ids = tokenizer(\n",
    "    \"Studies have been shown that owning a dog is good for you\", return_tensors=\"pt\"\n",
    ").input_ids.to(device)  # Batch size 1\n",
    "decoder_input_ids = tokenizer(\"Studies show that\", return_tensors=\"pt\").input_ids.to(device)  # Batch size 1\n",
    "\n",
    "# preprocess: Prepend decoder_input_ids with start token which is pad token for T5Model.\n",
    "# This is not needed for torch's T5ForConditionalGeneration as it does this internally using labels arg.\n",
    "decoder_input_ids = model._shift_right(decoder_input_ids)\n",
    "\n",
    "# forward pass\n",
    "outputs = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids)\n",
    "last_hidden_states = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec6ffb5-6340-4969-a5c1-8097e0f20047",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-21T04:39:15.893467Z",
     "iopub.status.idle": "2024-02-21T04:39:15.894174Z",
     "shell.execute_reply": "2024-02-21T04:39:15.893972Z",
     "shell.execute_reply.started": "2024-02-21T04:39:15.893952Z"
    }
   },
   "outputs": [],
   "source": [
    "last_hidden_states.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42b62db-9a85-48c9-a6a5-742ef3d830f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T02:09:15.987469Z",
     "iopub.status.busy": "2024-02-18T02:09:15.986727Z",
     "iopub.status.idle": "2024-02-18T02:09:16.015524Z",
     "shell.execute_reply": "2024-02-18T02:09:16.014042Z",
     "shell.execute_reply.started": "2024-02-18T02:09:15.987397Z"
    },
    "scrolled": true
   },
   "source": [
    "## Evaluate on IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467a9aa1-d879-42c0-a4ff-659158c22ff3",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-21T04:39:15.896190Z",
     "iopub.status.idle": "2024-02-21T04:39:15.896596Z",
     "shell.execute_reply": "2024-02-21T04:39:15.896411Z",
     "shell.execute_reply.started": "2024-02-21T04:39:15.896392Z"
    }
   },
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"f1\")\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    return metric.compute(predictions=predictions,\n",
    "                          references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f540c18e-3420-4818-8cfa-2c106a6398e7",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-21T04:39:15.898203Z",
     "iopub.status.idle": "2024-02-21T04:39:15.898922Z",
     "shell.execute_reply": "2024-02-21T04:39:15.898729Z",
     "shell.execute_reply.started": "2024-02-21T04:39:15.898709Z"
    }
   },
   "outputs": [],
   "source": [
    "# eval\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../results/promting_T5\",\n",
    "    per_device_eval_batch_size=16,\n",
    "    evaluation_strategy=\"epoch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdde02df-d06e-42bd-ae6d-ab0c95f5547d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-21T04:39:15.900994Z",
     "iopub.status.idle": "2024-02-21T04:39:15.901536Z",
     "shell.execute_reply": "2024-02-21T04:39:15.901331Z",
     "shell.execute_reply.started": "2024-02-21T04:39:15.901311Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    eval_dataset=tokenized_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca4f132-7639-456a-b14d-2d1ffc12cbd2",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-21T04:39:15.902916Z",
     "iopub.status.idle": "2024-02-21T04:39:15.903328Z",
     "shell.execute_reply": "2024-02-21T04:39:15.903144Z",
     "shell.execute_reply.started": "2024-02-21T04:39:15.903125Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluation_results = trainer.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
